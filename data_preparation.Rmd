---
title: "Data Preparation"
author: ""
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cerulean
---

# Data Preparation 

```{r eval = TRUE, echo = FALSE, message = FALSE}

# Load libraries and set theme

library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Greenspace data

For more information on the dataset and its data dictionary, click [here](https://data.cityofnewyork.us/Recreation/Parks-Properties/enfh-gkve/about_data).

```{r greenspace import, message=FALSE}
greenspace_df = read_csv("./data/Parks_Properties_20241126.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() 
```

```{r check, include=FALSE}
greenspace_df #2051 obs. 34 variables

summary(greenspace_df) 
#90 NAs for acquisitiondate. Keep NAs.
#acquisitiondate (dttm), acres (dbl), borough (char), typecategory (char)
```

The original `greenspace_df` dataset (`r nrow(greenspace_df)` observations and `r ncol(greenspace_df)` variables) contains information on Greenspaces in NYC. 

Variables of interest include `acquisitiondate`, `acres`, `borough`, and `typecategory`.

**Data cleaning**

```{r greenspace clean, message=FALSE}
greenspace_clean = greenspace_df |>
  mutate(
    borough = case_match(borough, #renamed borough according to data dictionary
      "R" ~ "Staten Island",
      "Q" ~ "Queens",
      "X" ~ "Bronx",
      "B" ~ "Brooklyn",
      "M" ~ "Manhattan"),
    typecategory = as.factor(typecategory), #converted char variables into factors
    borough = as.factor(borough)) |>
  separate(acquisitiondate, into = c("year", "month", "day"), sep = "-") |>
  select(year, borough, acres, typecategory) |> 
  filter(year < 2022 | is.na(year))
```

```{r clean check, include=FALSE}
summary(greenspace_clean)
```

```{r Greenspace 2016-2018, message=FALSE}
#Greenspace dataset: 2016-2018
dataset1_gs = greenspace_clean |>
  filter(year < 2019 | is.na(year)) |> 
  group_by(year, borough) |>
  summarise(avg_acres_per_yr_bor = mean(acres, na.rm = TRUE), .groups = "drop")

dataset1_gs_calc = dataset1_gs |> 
  group_by(borough) |> 
  summarise(acres_sum = sum(avg_acres_per_yr_bor, na.rm = TRUE), .groups = "drop") |> 
  mutate(year_group = "2016-2018")
```

```{r Greenspace 2019-2021, message=FALSE}
#Greenspace dataset: 2019-2021
dataset2_gs = greenspace_clean |>
  filter(year < 2022 | is.na(year)) |>
  group_by(year, borough) |>
  summarise(avg_acres_per_yr_bor = mean(acres, na.rm = TRUE), .groups = "drop")

dataset2_gs_calc = dataset2_gs |> 
  group_by(borough) |> 
  summarise(acres_sum = sum(avg_acres_per_yr_bor, na.rm = TRUE), .groups = "drop") |> 
  mutate(year_group = "2019-2021")
```

```{r merge, message=FALSE}
#bind 
total_acres = bind_rows(dataset1_gs_calc, dataset2_gs_calc)
  
#Final dataset
Greenspace_data = total_acres |>
  pivot_wider(names_from = year_group,
              values_from = acres_sum)
```

The final Greenspace dataset (`Greenspace_data`) includes `r nrow(greenspace_df)` observations and `r ncol(greenspace_df)` variables. Variables include `borough`, `2016-2018`, and `2019-2021`. Entries represent total acres of greenspace.

## Temperature data

used this [website](https://open-meteo.com/en/docs/historical-weather-api) and recorded the coordinates of 5 boroughs and extracted the temperatrue information by daily in a timeframe between 2016 and 2021.


```{r}

manhattan = read_csv("data/manhattan.csv",skip = 2) |>
  mutate(Borough = "Manhattan") |> 
  janitor::clean_names()

bronx = read_csv("data/bronx.csv",skip = 2) |>
  mutate(Borough = "Bronx") |> 
  janitor::clean_names()

brooklyn = read_csv("data/brooklyn.csv",skip = 2) |>
  mutate(Borough = "Brooklyn") |> 
  janitor::clean_names()

queens = read_csv("data/queens.csv",skip = 2) |>
  mutate(Borough = "Queens") |> 
  janitor::clean_names()

staten_island = read_csv("data/staten_island.csv",skip = 2) |>
  mutate(Borough = "Staten Island") |> 
  janitor::clean_names()
```

I then merged the data by borough and divided into two groups to compare.

```{r}
all_temp = bind_rows(manhattan, bronx, brooklyn, queens, staten_island) |> 
  mutate(borough = as.factor(borough)) |>
  mutate(date = as.Date(time, format = "%Y-%m-%d")) |> 
  mutate(data_years = ifelse(year(date) %in% 2016:2018, "2016-2018", "2019-2021")) |> 
  select(temperature_2m_max_c:data_years) |> 
  group_by(data_years, borough) |>
  summarise(avg_temperature = mean(temperature_2m_mean_c, na.rm = TRUE))
```

## Full data

```{r eval = FALSE}
full_data = bind_rows(ed_2016_2018, ed_2019_2021) |> 
  left_join(all_temp, by = c("data_years","borough"), relationship = "many-to-many") |> 
  left_join(tidy_analysis_pm, by = c("data_years", "borough"), relationship = "many-to-many") |> 
  left_join(total_acres, by = c("data_years","borough"), relationship = "many-to-many") |> 
  mutate(data_years = as.factor(data_years),
         borough = as.factor(borough),
         zip_code = as.factor(zip_code),
         indicator = as.factor(indicator),
         zip_code_rate = as.numeric(zip_code_rate)) |> 
  drop_na()

#dropped 74 NAs in zip_code_rate

full_data_ed = full_data |> 
  filter(indicator == "ed_visits_rate")

full_data_hosp = full_data |> 
  filter(indicator == "hosp_rate")

# Start from here

full_data2 = full_data |> 
  group_by(indicator, borough, data_years) |> 
  mutate(borough_rate = mean(zip_code_rate, na.rm = TRUE)) |> 
  ungroup()

summary(full_data)



write.csv(full_data, "data/NYC_total.csv", row.names = FALSE)
```

```{r eval = FALSE}

#ED and hospitalization rate between year groups and borough

ggplot(full_data, aes(x = data_years, y = zip_code_rate, fill = borough)) +
  geom_violin(trim = FALSE, alpha = 0.7) +
  facet_wrap( ~ indicator) +
  labs(title = "Distribution of ED, Hospitalization Rates Between Year Groups and Zipcode",
       x = "Year Group",
       y = "Rate",
       fill = "Borough") +
  theme_minimal()

#ED and Hospitalization rate histogram between year groups and borough

library(plotly)

a = ggplot(full_data2, aes(x = data_years, y = borough_rate, fill = borough)) +
  geom_col(position = "dodge") +
  facet_wrap( ~ indicator) +
  labs(
    title = "Borough ED, Hospitalization Rate by Year Group",
    x = "Year",
    y = "Rate",
    fill = "Borough"
  ) +
  theme_minimal()

ggplotly(a)

#Average temperature by date group and borough

ggplot(data = all_temp, aes(x = data_years, y = avg_temperature, color = borough)) +
  geom_point(size = 3) +
  geom_line(aes(group = borough), size = 1) +
  labs(title = "Average Temperature by Date Group and Borough",
       x = "Date Group",
       y = "Average Temperature") +
  theme_minimal()

#Average PM2.5 by date group and borough

ggplot(full_data, aes(x = data_years, y = average_pm2.5, color = borough)) +
  geom_point(size = 3) +
  geom_line(aes(group = borough), size = 1) +
  labs(title = "Average PM2.5 by Date Group and Borough",
       x = "Date Group",
       y = "Average PM2.5") +
  theme_minimal()

# ED visit linear regression

fit = lm(zip_code_rate ~ average_pm2.5 + avg_temperature + borough, data = full_data_ed)
summary(fit)

fit2 = lm(zip_code_rate ~ average_pm2.5 + avg_temperature + borough + percentage, data = full_data_hosp)
summary(fit2)

# try analysis with one exposure at a time by borough



```